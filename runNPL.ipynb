{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7c573c4-0f12-42b5-be94-ad1e7a9b9c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import NaiveBayesClassifier as nbc\n",
    "from nltk.classify import accuracy\n",
    "from pythainlp.tokenize import word_tokenize\n",
    "import codecs\n",
    "from itertools import chain\n",
    "import pickle\n",
    "#from pythainlp.transliterate import romanize\n",
    "#from pythainlp.translate import download_model_all\n",
    "from pythainlp.summarize import summarize\n",
    "import pandas as pd\n",
    "import time\n",
    "#from pandarallel import pandarallel\n",
    "from math import sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "365dfc89-0a4f-4050-bc3d-6a4b2709e728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Program\n"
     ]
    }
   ],
   "source": [
    "print(\"Start Program\")\n",
    "f = open('finalized_model.pickle', 'rb')\n",
    "classifier = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('vocabulary_model.pickle', 'rb')\n",
    "vocabulary = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9be5d9c-f531-491e-ac34-5b2565c4bca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Predict\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "print(\"Run Predict\")\n",
    "x=0\n",
    "def mypredit(fname):\n",
    "    global x\n",
    "    x =x+1\n",
    "    print(x)\n",
    "    test_sentence = fname\n",
    "    featurized_test_sentence={i:(i in word_tokenize(test_sentence.lower()))for i in vocabulary}\n",
    "    return classifier.classify(featurized_test_sentence)\n",
    "\n",
    "df = pd.read_csv('28_08_2023 17_35_12.csv')\n",
    "df.head()\n",
    "df['Result'] = df['text'].apply(mypredit)\n",
    "df.to_csv('28_08_2023 17_35_12P.csv')\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a1485b2-256c-4ecd-a72f-21524d1481a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved safe JSON vocabulary: vocabulary_words.json\n"
     ]
    }
   ],
   "source": [
    "import json, pickle\n",
    "\n",
    "PICKLE_PATH = \"vocabulary_model.pickle\"\n",
    "JSON_PATH   = \"vocabulary_words.json\"\n",
    "\n",
    "with open(PICKLE_PATH, \"rb\") as f:\n",
    "    vocab = pickle.load(f)\n",
    "\n",
    "# แปลงเป็น list ถ้ายังเป็น set\n",
    "if isinstance(vocab, set):\n",
    "    vocab = sorted(list(vocab))\n",
    "\n",
    "with open(JSON_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(vocab, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"✅ Saved safe JSON vocabulary:\", JSON_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c6bb0d7-c2dc-467c-b55a-47b5849a93ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Program (safe JSON)\n",
      "Run Predict\n",
      "100\n",
      "ok -> 28_08_2023 17_35_12P.csv\n"
     ]
    }
   ],
   "source": [
    "import json, math\n",
    "import pandas as pd\n",
    "from pythainlp.tokenize import word_tokenize\n",
    "\n",
    "MODEL_JSON = \"finalized_model_nltk_nb.json\"\n",
    "VOCAB_JSON = \"vocabulary_words.json\"\n",
    "INPUT_CSV  = \"28_08_2023 17_35_12.csv\"\n",
    "OUTPUT_CSV = \"28_08_2023 17_35_12P.csv\"\n",
    "\n",
    "# ---------- โหลดโมเดล NB ที่แปลงเป็น JSON ----------\n",
    "def load_safe_nb(json_path: str) -> dict:\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        M = json.load(f)\n",
    "    assert M.get(\"model_type\") == \"nltk_naive_bayes\", \"ไฟล์โมเดลไม่ใช่ฟอร์แมต NLTK NB\"\n",
    "    # บังคับชนิด float\n",
    "    M[\"label_priors\"] = {k: float(v) for k, v in M[\"label_priors\"].items()}\n",
    "    for lbl, d in M[\"feature_probs\"].items():\n",
    "        for fname, bucket in d.items():\n",
    "            for val, p in list(bucket.items()):\n",
    "                bucket[val] = float(p)\n",
    "    M[\"smoothing_epsilon\"] = float(M.get(\"smoothing_epsilon\", 1e-12))\n",
    "    return M\n",
    "\n",
    "def predict_proba_safe_nb(M: dict, features: dict) -> dict:\n",
    "    labels = M[\"labels\"]\n",
    "    priors = M[\"label_priors\"]\n",
    "    fprobs = M[\"feature_probs\"]\n",
    "    eps = float(M[\"smoothing_epsilon\"])\n",
    "\n",
    "    logps = []\n",
    "    for lbl in labels:\n",
    "        lp = math.log(max(priors.get(lbl, eps), eps))\n",
    "        # ตรงตามโค้ดเก่า: ใส่ทุก feature ใน vocabulary เป็น True/False\n",
    "        for fname, fval in features.items():\n",
    "            bucket = fprobs.get(lbl, {}).get(fname, {})\n",
    "            p = float(bucket.get(str(fval), eps))  # คีย์เป็นสตริง \"True\"/\"False\"\n",
    "            lp += math.log(max(p, eps))\n",
    "        logps.append(lp)\n",
    "\n",
    "    # softmax\n",
    "    m = max(logps)\n",
    "    exps = [math.exp(lp - m) for lp in logps]\n",
    "    Z = sum(exps) or 1.0\n",
    "    probs = [e / Z for e in exps]\n",
    "    return dict(zip(labels, probs))\n",
    "\n",
    "def predict_safe_nb(M: dict, features: dict):\n",
    "    probs = predict_proba_safe_nb(M, features)\n",
    "    return max(probs.items(), key=lambda kv: kv[1])[0], probs\n",
    "\n",
    "# ---------- โหลด vocabulary ----------\n",
    "def load_vocabulary(path: str):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        vocab = json.load(f)\n",
    "    # เผื่อไฟล์เป็น set/list ปนกัน ให้เป็น list ธรรมดา\n",
    "    return list(vocab)\n",
    "\n",
    "# ---------- แปลงข้อความ -> ฟีเจอร์ (เหมือนโค้ดเก่า) ----------\n",
    "def featurize(text: str, vocabulary) -> dict:\n",
    "    tokens = set(word_tokenize(str(text).lower()))\n",
    "    # เหมือนเดิมเป๊ะ: {i: (i in tokens) for i in vocabulary}\n",
    "    return {w: (w in tokens) for w in vocabulary}\n",
    "\n",
    "# ---------- main ----------\n",
    "def main():\n",
    "    print(\"Start Program (safe JSON)\")\n",
    "    M = load_safe_nb(MODEL_JSON)\n",
    "    vocabulary = load_vocabulary(VOCAB_JSON)\n",
    "    print(\"Run Predict\")\n",
    "\n",
    "    df = pd.read_csv(INPUT_CSV)\n",
    "    # สร้างคอลัมน์ผลลัพธ์\n",
    "    cnt = 0\n",
    "    def _predict_one(txt):\n",
    "        nonlocal cnt\n",
    "        cnt += 1\n",
    "        if cnt % 100 == 0:\n",
    "            print(cnt)\n",
    "        feats = featurize(txt, vocabulary)\n",
    "        yhat, _ = predict_safe_nb(M, feats)\n",
    "        return yhat\n",
    "\n",
    "    df[\"Result\"] = df[\"text\"].apply(_predict_one)\n",
    "    df.to_csv(OUTPUT_CSV, index=False, encoding=\"utf-8-sig\")\n",
    "    print(\"ok ->\", OUTPUT_CSV)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeceb34c-e3a5-4111-933e-67dcfc5c4d69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
